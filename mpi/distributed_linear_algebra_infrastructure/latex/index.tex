In this document we provide an overview of {\ttfamily oomph-\/lib\textquotesingle{}s} distributed linear algebra framework, discussing its design and key functionality. The aim of this framework is to facilitate the parallel (distributed) execution of linear algebra type operations with little (or no) user intervention. This requires all linear algebra data and computations to be distributed over all available processes.

We begin by defining the {\ttfamily Oomph\+Communicator}, a class that is fundamental to distributed computing in {\ttfamily oomph-\/lib}. Next we discuss the class {\ttfamily Linear\+Algebra\+Distribution} which specifies the distribution of the data and computations over the available processes. In Sections \hyperlink{index_double_vector}{Double\+Vector}, \hyperlink{index_cr_double_matrix}{C\+R\+Double\+Matrix} and \hyperlink{index_distributed_linear_algebra_object}{Distributed\+Linear\+Algebra\+Object} we discuss {\ttfamily oomph-\/lib\textquotesingle{}s} distributed linear algebra objects including the key containers (matrices and vectors) and operators (solvers and preconditioners). Finally, we demonstrate how the distributed linear algebra framework is typically used in practice.

The primary aim of this document is to provide an overview of the design and functionality of distributed linear algebra capabilities in {\ttfamily oomph-\/lib}, and hence we do not discuss every method of every class; we refer the reader to the class documentation for a complete specification.\hypertarget{index_oomph_communicator}{}\section{Oomph\+Communicator}\label{index_oomph_communicator}
{\ttfamily Oomph-\/lib} employs M\+PI for distributed memory parallelisation. Fundamental to M\+PI is the communicator ( {\ttfamily M\+P\+I\+\_\+\+Comm} ) which determines which processes are involved in a parallel computation. Although {\ttfamily oomph-\/lib} is implemented in C++, the C M\+PI bindings are utilised. {\ttfamily Oomph-\/lib} provides the class {\ttfamily Oomph\+Communicator} as an object-\/oriented wrapper for a {\ttfamily M\+P\+I\+\_\+\+Comm}.

Calling {\ttfamily M\+P\+I\+\_\+\+Helpers\+::init(argc,argv)} is equivalent to calling {\ttfamily M\+P\+I\+\_\+\+Init(argc,argv)}. It initialises M\+PI ( i.\+e. calls {\ttfamily M\+P\+I\+\_\+\+Init(argc,argv)} ) and creates {\ttfamily oomph-\/lib\textquotesingle{}s} global communicator\+:

 
\begin{DoxyCodeInclude}
\textcolor{comment}{//===start\_of\_main=============================================================}
\textcolor{comment}{/// Driver code for generic mpi stuff}
\textcolor{comment}{}\textcolor{comment}{//=============================================================================}
\textcolor{keywordtype}{int} main(\textcolor{keywordtype}{int} argc, \textcolor{keywordtype}{char}* argv[])
\{

  \textcolor{comment}{// Initialise MPI}
  MPI\_Helpers::init(argc,argv);

\end{DoxyCodeInclude}


The newly created communicator is available via a {\ttfamily M\+P\+I\+\_\+\+Helpers} class static method\+:


\begin{DoxyCodeInclude}
  \textcolor{comment}{// Get the global oomph-lib communicator }
  \textcolor{keyword}{const} OomphCommunicator* \textcolor{keyword}{const} comm\_pt = MPI\_Helpers::communicator\_pt();

\end{DoxyCodeInclude}


and is equivalent to the {\ttfamily M\+P\+I\+\_\+\+C\+O\+M\+M\+\_\+\+W\+O\+R\+LD} communicator in that it represents all the processes that {\ttfamily oomph-\/lib} knows about. By default, this communicator contains exactly the same set of processes as {\ttfamily M\+P\+I\+\_\+\+C\+O\+M\+M\+\_\+\+W\+O\+R\+LD}.

The {\ttfamily Oomph\+Communicator} provides a number of access functions to communicator data including the rank of the process and the number of the processes\+:


\begin{DoxyCodeInclude}

  \textcolor{comment}{// Get rank and total number of processors. }
  \textcolor{keywordtype}{unsigned} my\_rank = comm\_pt->my\_rank();
  \textcolor{keywordtype}{unsigned} nproc = comm\_pt->nproc();

  \textcolor{comment}{// Tell us who you are...}
  oomph\_info << \textcolor{stringliteral}{"I'm rank "} << my\_rank << \textcolor{stringliteral}{" on a total of "}
             << nproc << \textcolor{stringliteral}{" processors"} << std::endl;

\end{DoxyCodeInclude}
\hypertarget{index_linear_algebra_distribution}{}\section{Linear\+Algebra\+Distribution}\label{index_linear_algebra_distribution}
Distributed memory parallelisation requires data and computations to be distributed over the available processes in some way. In this document we are solely interested in distributed linear algebra. We choose to distribute the linear algebra objects row-\/wise, and constrain the distribution such that each process is associated with a single contiguous set of rows. The class {\ttfamily Linear\+Algebra\+Distribution} allows the specification of such a distribution.

The distribution is defined by two integers defining the first global row and the number of local rows associated with a process. This data is sufficient to allow a mapping between a global row number and a local row number on a particular process.

To construct a {\ttfamily Linear\+Algebra\+Distribution} in which 100 rows are uniformly distributed across the set of processes specified by {\ttfamily comm\+\_\+pt} we write\+:


\begin{DoxyCodeInclude}



  
  \textcolor{comment}{// Create a uniformly distributed LinearAlgebraDistribution}
  \textcolor{comment}{// 100 global rows are uniformly distributed accross the processes of }
  \textcolor{comment}{// comm\_pt}
  \textcolor{keywordtype}{unsigned} nrow\_global = 100;
  LinearAlgebraDistribution distributed\_distribution(comm\_pt,
                                                     nrow\_global); 

  \textcolor{comment}{// Show us how many rows this processor holds}
  oomph\_info << \textcolor{stringliteral}{"distributed distribution: first\_row and nrow\_local: "}
             << distributed\_distribution.first\_row() << \textcolor{stringliteral}{" "} 
             << distributed\_distribution.nrow\_local() 
             << std::endl;

\end{DoxyCodeInclude}


In this example, if run on four processes, the first 25 rows are associated with process 0, the next 25 rows are on process 1 and so on. In general, in a uniform distribution of $n_r$ global rows over $n_p$ processes the first row on process $p=0,1,\ldots,(n_p-1)$ is $\lfloor \frac{pn_r}{n_p}\rfloor$. It is also possible the specify alternative user defined distributions; see the class documentation for details.

An optional third ( {\ttfamily bool} ) argument (default\+: true) in the constructor indicates that we require a distributed linear algebra distribution. However, on some occasions we may want to replicate all rows of a linear algebra object on all processes. This is achieved by simply making the third argument {\ttfamily false} (non-\/distributed)\+:


\begin{DoxyCodeInclude}
  

  \textcolor{comment}{// Construct an empty distribution object (does not specify a distribution)}
  LinearAlgebraDistribution locally\_replicated\_distribution;
  
  \textcolor{comment}{// Build a locally replicated distribution such that every row is available}
  \textcolor{comment}{// on every process}
  \textcolor{keywordtype}{bool} distributed=\textcolor{keyword}{false};
  locally\_replicated\_distribution.build(comm\_pt,nrow\_global,distributed);
  
  \textcolor{comment}{// Show us how many rows this processor holds}
  oomph\_info << \textcolor{stringliteral}{"locally replicated distribution: first\_row and nrow\_local: "}
             << locally\_replicated\_distribution.first\_row() << \textcolor{stringliteral}{" "} 
             << locally\_replicated\_distribution.nrow\_local() 
             << std::endl;

\end{DoxyCodeInclude}


This example illustrates two other features of {\ttfamily Linear\+Algebra\+Distribution}. Firstly, the default constructor creates an empty distribution, and secondly for every (non-\/default) constructor there is an equivalent {\ttfamily build}(...) method to \char`\"{}re-\/construct\char`\"{} the object.

The state of the object is accessible through a range of methods.


\begin{DoxyCodeInclude}
  
  \textcolor{comment}{// Get the number of local rows on this process}
  \textcolor{keywordtype}{unsigned} nrow\_local = distributed\_distribution.nrow\_local();
  
  \textcolor{comment}{// Get the first row on this process}
  \textcolor{keywordtype}{unsigned} first\_row = distributed\_distribution.first\_row();
  
  \textcolor{comment}{// Get the number of global rows}
  nrow\_global = distributed\_distribution.nrow();
  
  \textcolor{comment}{// Is this distributed (true) or locally replicated (false)}
  distributed = distributed\_distribution.distributed();
  
  \textcolor{comment}{// Does this object specify a distribution}
  \textcolor{keywordtype}{bool} built = distributed\_distribution.built();

\end{DoxyCodeInclude}


The {\ttfamily built()} method indicates if the object specifies a distribution, or is empty.\hypertarget{index_double_vector}{}\section{Double\+Vector}\label{index_double_vector}
The simplest distributed linear algebra object is {\ttfamily Double\+Vector}, a distributed vector of {\ttfamily doubles} developed specifically for linear algebra (It differs from a {\ttfamily Vector$<$double$>$} which simply provides a container for {\ttfamily doubles} ). For example, the following command constructs a {\ttfamily Double\+Vector} with a uniform distribution (specified by the distributed {\ttfamily Linear\+Algebra\+Distribution} defined in the previous section) and unit elements\+:


\begin{DoxyCodeInclude}
  


  \textcolor{comment}{// Construct a uniformly distributed DoubleVector with unit elements}
  DoubleVector my\_vector(distributed\_distribution,1.0);

\end{DoxyCodeInclude}


To access the vector elements the {\ttfamily operator}\mbox{[}\mbox{]} is implemented. For example to increment every element by one\+:


\begin{DoxyCodeInclude}
  
  \textcolor{comment}{// Increment every element of my\_vector on this process by 1}
  nrow\_local = my\_vector.distribution\_pt()->nrow\_local();
  \textcolor{keywordflow}{for} (\textcolor{keywordtype}{unsigned} i = 0; i < nrow\_local; i++)
   \{
    my\_vector[i]+=1.0;
   \}

\end{DoxyCodeInclude}


It is the {\ttfamily oomph-\/lib} convention that the data in {\ttfamily Double\+Vector} (and all other distributed linear algebra object) is accessed using local indices. The following loop documents the local row number, the global row number, and the value of the elements on each process\+:


\begin{DoxyCodeInclude}
  
  \textcolor{comment}{// Document elements on this process in my\_vector}
  nrow\_local = my\_vector.distribution\_pt()->nrow\_local();
  first\_row = my\_vector.distribution\_pt()->first\_row();
  \textcolor{keywordflow}{for} (\textcolor{keywordtype}{unsigned} i = 0; i < nrow\_local; i++)
   \{
    oomph\_info << \textcolor{stringliteral}{"local row "} << i 
               << \textcolor{stringliteral}{" is global row "} << first\_row+i 
               << \textcolor{stringliteral}{" and has value "} << my\_vector[i] << std::endl; 
   \}

\end{DoxyCodeInclude}


To change the distribution of a {\ttfamily Double\+Vector} while retaining the data, we provide the {\ttfamily redistribute}(...) method. For example to change {\ttfamily my\+\_\+vector} from uniformly distributed to locally replicated\+:


\begin{DoxyCodeInclude}

  \textcolor{comment}{// Redistribute my\_vector such that it is locally replicated on all processes}
  my\_vector.redistribute(&locally\_replicated\_distribution);

\end{DoxyCodeInclude}


Just like the {\ttfamily Linear\+Algebra\+Distribution}, we provide {\ttfamily build()} methods that mirror the behaviour of all non-\/default constructors. For example to revert {\ttfamily my\+\_\+vector} to a uniform distribution with unit elements\+:


\begin{DoxyCodeInclude}
  
  \textcolor{comment}{// (Re)build my\_vector such that it is uniformly distributed over all}
  \textcolor{comment}{// processes}
  my\_vector.build(distributed\_distribution,1.0);

\end{DoxyCodeInclude}


It is important to differentiate between {\ttfamily build}(...) and {\ttfamily redistribute}(...); calling {\ttfamily build}(...) deletes the existing data, effectively re-\/constructing the object, whereas {\ttfamily redistribute}(...) retains the vector\textquotesingle{}s data.

Like the {\ttfamily Linear\+Algebra\+Distribution}, a {\ttfamily Double\+Vector} need not contain any data. To generate an object in this state, we could instantiate an object using the default constructor or call the {\ttfamily clear()} method\+:


\begin{DoxyCodeInclude}

  \textcolor{comment}{// Construct an empty DoubleVector}
  DoubleVector another\_vector;
  
  \textcolor{comment}{// Clear all data from an existing DoubleVector}
  my\_vector.clear();

\end{DoxyCodeInclude}


Again the {\ttfamily built()} method returns the state of the object and indicates if it contains any data.\hypertarget{index_cr_double_matrix}{}\section{C\+R\+Double\+Matrix}\label{index_cr_double_matrix}
{\ttfamily C\+R\+Double\+Matrix} is the only distributed matrix in {\ttfamily oomph-\/lib}. It employs sparse compressed row storage to store {\ttfamily double} coefficients.

A {\ttfamily C\+R\+Double\+Matrix} has three fundamental states\+:


\begin{DoxyItemize}
\item A {\ttfamily C\+R\+Double\+Matrix} can have no distribution or coefficients in which case {\ttfamily my\+\_\+matrix-\/$>$distribution\+\_\+built()} and {\ttfamily my\+\_\+matrix-\/$>$built()} are both {\ttfamily false}.
\item A (built) distribution but no coefficients in which case {\ttfamily my\+\_\+matrix-\/$>$distribution\+\_\+built()} is {\ttfamily true} but {\ttfamily my\+\_\+matrix-\/$>$built()} is still {\ttfamily false}.
\item A (built) distribution and coefficients in which case {\ttfamily my\+\_\+matrix-\/$>$distribution\+\_\+built()} and {\ttfamily my\+\_\+matrix-\/$>$built()} are both {\ttfamily true}.
\end{DoxyItemize}

For example, to construct an empty matrix we call\+:


\begin{DoxyCodeInclude}

  
  \textcolor{comment}{// Construct an empty CRDoubleMatrix}
  CRDoubleMatrix my\_matrix;

\end{DoxyCodeInclude}


To specify the distribution as defined by the {\ttfamily Linear\+Algebra\+Distribution} {\ttfamily distributed\+\_\+distribution} we write\+:


\begin{DoxyCodeInclude}

  \textcolor{comment}{// Specify that the rows be uniformly distributed}
  my\_matrix.build(&distributed\_distribution);

\end{DoxyCodeInclude}


The distribution has now been specified but the coefficients have not. Like the {\ttfamily Double\+Vector}, rows are indexed locally and hence the coefficients rows must be indexed locally. For example, to populate {\ttfamily my\+\_\+matrix} as a square identity matrix, we write\+:


\begin{DoxyCodeInclude}

  \textcolor{comment}{// Vector of coefficient of value 1.0}
  Vector<double> values(nrow\_local,1.0);
  
  \textcolor{comment}{// Column indices corresponding to values}
  Vector<int> column\_indices(nrow\_local);
  
  \textcolor{comment}{// Index of vectors values and column\_indices where the i-th row starts}
  \textcolor{comment}{// (each row contains one coefficient)}
  Vector<int> row\_start(nrow\_local+1);
  
  \textcolor{comment}{// populate column\_indices and row\_start}
  \textcolor{keywordflow}{for} (\textcolor{keywordtype}{unsigned} i = 0; i < nrow\_local; ++i)
   \{
    column\_indices[i]=first\_row+nrow\_local;
    row\_start[i]=i;
   \}
  row\_start[nrow\_local]=nrow\_local;
  
  \textcolor{comment}{// Build the (square) matrix}
  \textcolor{keywordtype}{unsigned} ncol = nrow\_global;
  my\_matrix.build(ncol,values,column\_indices,row\_start);

\end{DoxyCodeInclude}


We note that the column indices are global because only the rows are distributed. The assembly of a {\ttfamily C\+R\+Double\+Matrix} is now complete.

We constructed the matrix in two stages by first specifying the distribution and then specifying the coefficients. However it is possible to perform this operation in just one step, by using the appropriate constructor or {\ttfamily build}(...) method, for example\+:


\begin{DoxyCodeInclude}
  
  CRDoubleMatrix my\_matrix2(&distributed\_distribution,ncol,values,
                           column\_indices,row\_start);

\end{DoxyCodeInclude}
\hypertarget{index_distributed_linear_algebra_object}{}\section{Distributed\+Linear\+Algebra\+Object}\label{index_distributed_linear_algebra_object}
In this section we introduce the class {\ttfamily Distributed\+Linear\+Algebra\+Object}, a base class for all distributed linear algebra objects. This class encapsulates a {\ttfamily Linear\+Algebra\+Distribution}, provides (protected) access to derived classes to update ( {\ttfamily build\+\_\+distribution}(...) ) and clear ( {\ttfamily clear()} ) the stored distribution. Secondly, it provides methods to simplify access to commonly used {\ttfamily Linear\+Algebra\+Distribution} data. For example, because a {\ttfamily C\+R\+Double\+Matrix} is a {\ttfamily Distributed\+Linear\+Algebra\+Object},


\begin{DoxyCodeInclude}
  
  \textcolor{comment}{// Get the first (global) row of my\_matrix on this process}
  first\_row =  my\_matrix2.distribution\_pt()->first\_row();

\end{DoxyCodeInclude}


can be replaced with


\begin{DoxyCodeInclude}
  
  \textcolor{comment}{// Get the first (global) row of my\_matrix on this process}
  first\_row =  my\_matrix2.first\_row();

\end{DoxyCodeInclude}


{\ttfamily Distributed\+Linear\+Algebra\+Objects} can be divided into two types\+: containers and operators. We have already reviewed the containers {\ttfamily Double\+Vector} and {\ttfamily C\+R\+Double\+Matrix}. A wide range of operator classes have been implemented in {\ttfamily oomph-\/lib} to operate on these containers. In particular, all {\ttfamily Linear\+Solvers}, {\ttfamily Iterative\+Linear\+Solvers} and {\ttfamily Preconditioners} (discussed in the \href{../../../linear_solvers/html/index.html}{\tt Linear Solvers Tutorial}) are {\ttfamily Distributed\+Linear\+Algebra\+Objects}. We finish this section by reviewing the key linear algebra operators\+:


\begin{DoxyItemize}
\item {\ttfamily Super\+L\+U\+Solver} is a {\ttfamily Linear\+Solver} wrapper to both the \href{http://crd.lbl.gov/~xiaoye/SuperLU/#superlu}{\tt {\ttfamily Super\+LU}} direct solver and the \href{http://crd.lbl.gov/~xiaoye/SuperLU/#superlu_dist}{\tt {\ttfamily Super\+LU Dist}} distributed direct solver. By default, whenever possible this class will automatically perform distributed solves.
\item {\ttfamily Trilinos\+Aztec\+O\+O\+Solver} is an {\ttfamily Iterative\+Linear\+Solver} wrapper to the \href{http://trilinos.sandia.gov/packages/aztecoo}{\tt {\ttfamily Trilinos Aztec\+OO}} package implementation of distributed Krylov methods including CG, G\+M\+R\+ES and Bi\+C\+G\+Stab.
\item {\ttfamily Trilinos\+M\+L\+Preconditioner} is a wrapper to the distributed \href{http://trilinos.sandia.gov/packages/ml}{\tt Trilinos ML A\+MG preconditioners}.
\item {\ttfamily Trilinos\+I\+F\+P\+A\+C\+K\+Preconditioner} is a wrapper to the distributed \href{http://trilinos.sandia.gov/packages/ifpack}{\tt Trilinos I\+F\+P\+A\+CK preconditioners}.
\item {\ttfamily Hypre\+Preconditioner} is a wrapper to the distributed \href{https://computation.llnl.gov/casc/linear_solvers/sls_hypre.html}{\tt {\ttfamily Hypre Scalable Linear Solvers}} package, of particular interest is the classical A\+MG implementation {\ttfamily Boomer\+A\+MG}.
\item {\ttfamily Matrix\+Vector\+Product} is a wrapper to the \href{http://trilinos.sandia.gov/packages/epetra/}{\tt {\ttfamily Trilinos Epetra}} distributed matrix-\/vector product implementation.
\end{DoxyItemize}\hypertarget{index_distributed_linear_algebra_in_practice}{}\section{Distributed Linear Algebra In Practice}\label{index_distributed_linear_algebra_in_practice}
Having discussed {\ttfamily oomph-\/lib\textquotesingle{}s} linear algebra infrastructure, we finally remark that {\ttfamily oomph-\/lib} is implemented such that linear algebra in {\ttfamily oomph-\/lib} is automatically distributed if executed under M\+PI on multiple processes. Specifically, a user should not need to specify either a {\ttfamily Linear\+Algebra\+Distribution} or a {\ttfamily Oomph\+Communicator}, unless they wish to customise some aspect of the parallelisation.

All functionality is designed such that if a user does not specify a {\ttfamily Linear\+Algebra\+Distribution}, then as much data and computation as possible will be uniformly distributed over all available processes.

As an example, we consider the {\ttfamily Problem} method {\ttfamily get\+\_\+jacobian}(...). If the user does not specify a return distribution for the Jacobian and residuals, then {\ttfamily oomph-\/lib} will uniformly distribute both containers.


\begin{DoxyCodeInclude}





  \textcolor{comment}{// Set up a problem: }
  \textcolor{comment}{// Solve a 1D Poisson problem using a source function that generates}
  \textcolor{comment}{// a fish shaped exact solution}
  \textcolor{keywordtype}{unsigned} n\_element=40; 
  OneDPoissonProblem<QPoissonElement<1,4> > 
   problem(n\_element,FishSolnOneDPoisson::source\_function);
    
  \textcolor{comment}{// Get the residual and Jacobian, by default both are uniformly distributed}
  \textcolor{comment}{// over all available processes}
  my\_vector.clear();
  my\_matrix.clear();
  
  \textcolor{comment}{// Get the Jacobian}
  problem.get\_jacobian(my\_vector,my\_matrix);
  
  oomph\_info 
   << \textcolor{stringliteral}{"Uniformly distributed residual vector: first\_row and nrow\_local: "} 
   << my\_vector.first\_row() << \textcolor{stringliteral}{" "} 
   << my\_vector.nrow\_local() << std::endl
   << \textcolor{stringliteral}{"Uniformly distributed jacobian matrix: first\_row, nrow\_local and nnz: "} 
   << my\_matrix.first\_row() << \textcolor{stringliteral}{" "} 
   << my\_matrix.nrow\_local() << \textcolor{stringliteral}{" "} 
   << my\_matrix.nnz() << \textcolor{stringliteral}{" "} 
   << std::endl;

\end{DoxyCodeInclude}


On the other hand, a user can specify a return distribution by setting the distribution of the matrix and vector prior to calling {\ttfamily get\+\_\+jacobian}(...).


\begin{DoxyCodeInclude}


  \textcolor{comment}{// Request locally replicated residual and Jacobian from the problem}
  distributed=\textcolor{keyword}{false};
  LinearAlgebraDistribution locally\_replicated\_distribution\_for\_jac(
   comm\_pt,problem.ndof(),distributed);
  
  \textcolor{comment}{// Show us how many rows this processor holds}
  oomph\_info 
   << \textcolor{stringliteral}{"locally replicated distribution\_for\_jac: first\_row and nrow\_local: "}
   << locally\_replicated\_distribution\_for\_jac.first\_row() << \textcolor{stringliteral}{" "} 
   << locally\_replicated\_distribution\_for\_jac.nrow\_local() 
   << std::endl;

\end{DoxyCodeInclude}


We finally remark that because all linear algebra operations are automatically distributed, to parallelise {\ttfamily oomph-\/lib\textquotesingle{}s} Newton solve phase, the user need only run their executable under M\+PI on multiple processes.\hypertarget{index_sources}{}\section{Source files for this tutorial}\label{index_sources}

\begin{DoxyItemize}
\item The source files for this tutorial are located in the directory\+:~\newline
~\newline
\begin{center} \href{../../../../self_test/mpi/generic_mpi/}{\tt self\+\_\+test/mpi/generic\+\_\+mpi } \end{center} ~\newline

\item The driver code is\+: ~\newline
~\newline
\begin{center} \href{../../../../self_test/mpi/generic_mpi/generic_mpi_test.cc}{\tt self\+\_\+test/mpi/generic\+\_\+mpi/generic\+\_\+mpi\+\_\+test.\+cc } \end{center} 
\end{DoxyItemize}



 

 \hypertarget{index_pdf}{}\section{P\+D\+F file}\label{index_pdf}
A \href{../latex/refman.pdf}{\tt pdf version} of this document is available. \end{document}
